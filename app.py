from flask import Flask, render_template, request, Response, stream_with_context, jsonify
import json
import atexit
import sys
import os # è¨˜å¾—å°å…¥ os

# --- å°å…¥æ¨¡çµ„ ---
# å‡è¨­ main_app ä¸­åŒ…å«äº†æ‰€æœ‰æ ¸å¿ƒé‚è¼¯å’Œæ¨¡å‹é…ç½®
from main_app import (
    chat_with_dual_brain, 
    unload_model,
    text_to_speech,    
    speech_to_text,    
    identify_speaker,  
    search_memory,     
    add_memory         
)

# å°å…¥åœ–ç‰‡èˆ‡PDFè™•ç†å‡½æ•¸
from mcp_handler import process_uploaded_image, process_pdf_pipeline

app = Flask(__name__)
app.secret_key = 'your_secret_key' 

# ==============================================================================
# ğŸš¨ã€çµ‚æ¥µè§£æ³•ã€‘æš´åŠ›è§£é™¤å¤§å°é™åˆ¶ (ç¢ºä¿èƒ½ä¸Šå‚³å¤§å‹æª”æ¡ˆ/Base64)
# ==============================================================================
# å°‡ç¸½ä¸Šå‚³é™åˆ¶è¨­ç‚ºä¸€å€‹æ¥µå¤§å€¼ (16GB)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024 * 1024 
# å°‡è¡¨å–®è¨˜æ†¶é«”é™åˆ¶ (è™•ç† Base64 å­—ä¸²) è¨­ç‚º 1GB
app.config['MAX_FORM_MEMORY_SIZE'] = 1024 * 1024 * 1024 
app.config['MAX_HEADERS_LIST'] = 1024 * 1024 

# ------------------------------------------------------------------------------

chat_history = [] 
atexit.register(unload_model) 

@app.route("/")
def index():
    return render_template("index.html", history=chat_history)

@app.route("/chat", methods=["POST"])
def chat():
    # 1. ç²å–è¼¸å…¥
    try:
        user_text = request.form.get("user_input", "").strip()
        image_base64 = request.form.get("image_base64", "").strip()
        pdf_file = request.files.get("pdf_file")
        pdf_page = request.form.get("pdf_page", "1")
    except Exception as e:
        print(f"âŒ æ¥æ”¶è³‡æ–™å¤±æ•—: {e}")
        return Response(json.dumps({"text": f"âŒ è³‡æ–™å‚³è¼¸å¤±æ•—: {e}", "done": True}) + "\n", mimetype='application/jsonlines')
    
    audio_file_path = None
    identity_context = "ä½¿ç”¨è€…æ­£åœ¨ä½¿ç”¨æ–‡å­—ä»‹é¢èˆ‡ä½ äº¤è«‡" 
    
    # --- æ··åˆè¼¸å…¥é‚è¼¯ ---
    if user_text and not image_base64 and not pdf_file:
        print(f" [Webæ–‡å­—è¼¸å…¥]: {user_text}")
    elif not user_text and not image_base64 and not pdf_file: 
        print(" [WebèªéŸ³æ¨¡å¼]...")
        stt_result = speech_to_text() 
        if not stt_result:
            return Response(json.dumps({"text": "âŒ (æœªåµæ¸¬åˆ°èªéŸ³)", "done": True}) + "\n", mimetype='application/jsonlines')
        user_text, audio_file_path = stt_result
        if audio_file_path:
            is_master, score = identify_speaker(audio_file_path)
            identity_context = "èªè­˜çš„äºº" if is_master else "é™Œç”Ÿè¨ªå®¢"

    # --- åœ–ç‰‡è™•ç† ---
    if image_base64:
        vision_analysis = process_uploaded_image(image_base64, user_text)
        user_text = vision_analysis
        print(" [Webåœ–ç‰‡] å·²è½‰æ›ç‚ºæ–‡å­—æè¿°")

    # --- PDF è™•ç† ---
    if pdf_file:
        try:
            page_num = int(pdf_page)
            pdf_bytes = pdf_file.read() 
            print(f" ğŸ“„ [Web PDF] æ¥æ”¶åˆ°æª”æ¡ˆï¼Œå¤§å°: {len(pdf_bytes)/1024/1024:.2f} MB")
            pdf_analysis = process_pdf_pipeline(pdf_bytes, page_num, user_text)
            user_text = pdf_analysis
        except Exception as e:
            print(f"PDF éŒ¯èª¤: {e}")
            user_text = f"PDF è™•ç†ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    if "é€€å‡º" in user_text:
        return Response(json.dumps({"text": "æ°æ°ï¼", "done": True}) + "\n", mimetype='application/jsonlines')

    # 2. Prompt
    found_memories = search_memory(user_text, n_results=2)
    memory_str = "\n".join([f"- {m}" for m in found_memories]) if found_memories else "ç„¡ç›¸é—œå›æ†¶"
    recent_msgs = chat_history[-100:] 
    recent_chat_str = "\n".join([f"{msg['speaker']}: {msg['text']}" for msg in recent_msgs])

    system_prompt = (
        "ä½ å–œæ­¡è§£æ•¸å­¸é¡Œç›®ï¼Œçœ‹åˆ°é¡Œç›®æœƒå–œæ­¡æ¨å°ï¼Œä¸¦æ“…é•·ä½¿ç”¨ WolframAlpha\n"
        f"=== å°è©±å ´æ™¯è³‡è¨Š ===\n"
        f"èº«ä»½: {identity_context}\n"
        f"é•·æœŸè¨˜æ†¶:\n{memory_str}\n"
        f"æœ€è¿‘å°è©±:\n{recent_chat_str}\n"
    )

    history_log = "[ä½¿ç”¨è€…ä¸Šå‚³æª”æ¡ˆ]" if (image_base64 or pdf_file) else user_text
    chat_history.append({"speaker": "user", "text": history_log})

    # 3. é›™è…¦ç”Ÿæˆ
    try:
        response_stream = chat_with_dual_brain(system_prompt, user_text)
    except Exception as e:
        return Response(json.dumps({"text": f"âŒ Error: {e}", "done": True}) + "\n", status=500, mimetype='application/jsonlines')

    # 4. ä¸²æµå›æ‡‰
    def generate_response(stream):
        full_ai_response = ""
        in_think_block = False 
        
        if stream and hasattr(stream, 'iter_lines'):
            for line in stream.iter_lines():
                if line:
                    try:
                        json_data = json.loads(line.decode('utf-8'))
                        chunk = json_data.get("message", {}).get("content", "")
                        
                        if chunk:
                            # --- <think> éæ¿¾æ¼”ç®—æ³• ---
                            content_to_yield = ""
                            temp_chunk = chunk
                            
                            while len(temp_chunk) > 0:
                                if not in_think_block:
                                    start_idx = temp_chunk.find("<think>")
                                    if start_idx != -1:
                                        content_to_yield += temp_chunk[:start_idx]
                                        in_think_block = True
                                        temp_chunk = temp_chunk[start_idx + 7:]
                                    else:
                                        content_to_yield += temp_chunk
                                        temp_chunk = ""
                                else:
                                    end_idx = temp_chunk.find("</think>")
                                    if end_idx != -1:
                                        in_think_block = False
                                        temp_chunk = temp_chunk[end_idx + 8:]
                                    else:
                                        temp_chunk = ""
                            
                            if content_to_yield:
                                full_ai_response += content_to_yield
                                yield json.dumps({"text": content_to_yield, "done": False}) + "\n"
                        if json_data.get("done"): break
                    except: break
        
        if full_ai_response.strip():
            chat_history.append({"speaker": "ai", "text": full_ai_response})
            add_memory(user_text, "User")
            add_memory(full_ai_response, "AI")
            yield json.dumps({"text": "", "done": True, "full_text": full_ai_response}) + "\n"
        else:
            yield json.dumps({"text": "(AI ç„¡å›æ‡‰)", "done": True}) + "\n"

    return Response(stream_with_context(generate_response(response_stream)), mimetype='application/jsonlines')

@app.route("/tts", methods=["POST"])
def generate_audio():
    """ç”ŸæˆéŸ³è¨Šæª”ä¸¦å‚³å› (å«é˜²å‘†æª¢æŸ¥)"""
    data = request.json
    text_to_speak = data.get("text", "")
    
    if not text_to_speak:
        return jsonify({"error": "No text provided"}), 400

    try:
        # å‘¼å« TTS
        audio_file_path = text_to_speech(text_to_speak)
        
        # æª¢æŸ¥æ˜¯å¦çœŸçš„æœ‰å›å‚³è·¯å¾‘ï¼Œä»¥åŠæª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not audio_file_path or not isinstance(audio_file_path, str):
            print(f"âš ï¸ TTS ç”Ÿæˆå¤±æ•—: text_to_speech å›å‚³äº† {type(audio_file_path)}")
            return jsonify({"error": "TTS generation failed (Internal Error)"}), 500
            
        if not os.path.exists(audio_file_path):
            print(f"âš ï¸ TTS æª”æ¡ˆæ‰¾ä¸åˆ°: {audio_file_path}")
            return jsonify({"error": "TTS file not found"}), 500

        # è®€å–æª”æ¡ˆ
        with open(audio_file_path, 'rb') as f:
            audio_data = f.read()
            
        return Response(audio_data, mimetype="audio/wav")
        
    except Exception as e:
        print(f"âŒ TTS è·¯ç”±ç™¼ç”ŸéŒ¯èª¤: {e}")
        return jsonify({"error": f"TTS exception: {str(e)}"}), 500

@app.errorhandler(413)
def request_entity_too_large(error):
    return jsonify({"error": "æª”æ¡ˆå¤ªå¤§", "detail": "Server rejected payload (413)"}), 413

if __name__ == "__main__":
    print("="*50)
    print(f"ğŸš€ Flask ä¼ºæœå™¨å•Ÿå‹•ä¸­...")
    print(f"ğŸ“‚ MAX_CONTENT_LENGTH è¨­å®šç‚º: {app.config['MAX_CONTENT_LENGTH']}")
    print(f"ğŸ§  MAX_FORM_MEMORY_SIZE è¨­å®šç‚º: {app.config['MAX_FORM_MEMORY_SIZE'] / (1024*1024):.2f} MB")
    print("="*50)
    
    app.run(debug=True, port=5000, threaded=False, use_reloader=False)